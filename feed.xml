<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2020-08-08T19:26:59+08:00</updated><id>/feed.xml</id><title type="html">MettyZ’s Blog</title><subtitle></subtitle><author><name>mettyz</name></author><entry><title type="html">Paper Reading Record 3</title><link href="/PR3.html" rel="alternate" type="text/html" title="Paper Reading Record 3" /><published>2020-08-08T00:00:00+08:00</published><updated>2020-08-08T00:00:00+08:00</updated><id>/PR3</id><content type="html" xml:base="/PR3.html">&lt;p&gt;(CVPR2019) &lt;a href=&quot;https://arxiv.org/pdf/1908.05436v3.pdf&quot;&gt;[Paper]&lt;/a&gt;&lt;/p&gt;

&lt;!--more--&gt;

&lt;blockquote&gt;
  &lt;p&gt;写在前面：文中包含个人理解，不保证正确，如理解有误，欢迎指正。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;main-idea&quot;&gt;Main Idea&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;使用 DCT 系数编码各个关节点在&lt;strong&gt;时序&lt;/strong&gt;上的信息&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;使用 GCN 建模关节点的&lt;strong&gt;空间&lt;/strong&gt;关联，且允许网络自适应地调整任意关节点间的连通权重&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;提出由于角度空间的表示存在二义性，基于欧拉角的评估标准不可靠&lt;/p&gt;

    &lt;p&gt;建议今后的工作采用基于3D位置的评估标准&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;基于RNN的方法存在的问题&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;并行能力差，训练难度较大&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;若每帧输入上帧预测结果，误差可能随着序列累积&lt;/p&gt;

        &lt;p&gt;若每帧输入GT监督，则易出现预测动作的不连续&lt;/p&gt;

        &lt;blockquote&gt;
          &lt;p&gt;&lt;em&gt;curriculum learning strategy&lt;/em&gt;&lt;/p&gt;

          &lt;p&gt;以一定概率输入GT作为教师监督，否则输入前一步预测结果&lt;/p&gt;

          &lt;p&gt;该策略可在一定程度上缓解上述问题&lt;/p&gt;
        &lt;/blockquote&gt;

        &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;如何编码时序信息&lt;/strong&gt;，是前馈神经网络在处理时序相关问题时必须考虑的问题&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;现有方法：通过在时序维度上进行卷积，但这将很大程度上依赖于卷积核的大小&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;本文方法：在轨迹空间中建模运动（而非姿态空间中）&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;更具体地，采用 离散余弦变换 (DCT) 编码时序信息，建模每个关节点的变化轨迹&lt;/p&gt;

        &lt;blockquote&gt;
          &lt;p&gt;&lt;strong&gt;离散余弦变换 Discrete Cosine Transform&lt;/strong&gt;&lt;/p&gt;

          &lt;p&gt;形式上看，DCT是一个线性可逆函数 $F:R^n\to R^n$&lt;/p&gt;

          &lt;p&gt;&lt;img src=&quot;../assets/img/2020-08-08-PR3_pic/image-20200807193035539.png&quot; alt=&quot;image-20200807193035539&quot; style=&quot;zoom: 80%;&quot; /&gt;&lt;/p&gt;

          &lt;p&gt;进一步，将 $f_0$ 乘以 $\frac{1}{\sqrt{2}}$ ，将使得DCT-II 成为正交矩阵。&lt;/p&gt;

          &lt;p&gt;​																					—— &lt;em&gt;From &lt;a href=&quot;https://zh.wikipedia.org/wiki/离散余弦变换&quot;&gt;Wiki&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;如何编码关节点间的空间依赖关系&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;现有方法及缺陷&lt;/p&gt;

        &lt;p&gt;​	1）基于骨架，无法建模远距离依赖&lt;/p&gt;

        &lt;p&gt;​	2）基于空间卷积，依赖于卷积核的大小&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;本文方法：图卷积，且允许网络自主学习节点间的连通关系&lt;/strong&gt;，而非预定义图的连接，从而能够解决上述两种问题&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;related-works&quot;&gt;Related Works&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;基于对抗网络的模型&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;主要思想：迫使生成器生成平滑的动作序列，使判别器无法分辨&lt;/p&gt;

        &lt;blockquote&gt;
          &lt;p&gt;是对RNN模型预测动作不连续问题的一种解决办法&lt;/p&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;缺陷：模型较复杂，训练难度较大，且难以扩展到新的数据集&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;图卷积网络 GCNs&lt;/strong&gt;&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;笔者对该领域暂不熟悉，下面简单直译论文的描述，仅作为阅读记录&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;GCN 领域的主要研究成果可分为 光谱(spectral) 与 非光谱(non-spectral) 方法&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;strong&gt;spectral 代表&lt;/strong&gt;&lt;/p&gt;

            &lt;p&gt;[1] Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In ICLR, 2017.&lt;/p&gt;

            &lt;blockquote&gt;
              &lt;p&gt;采用基于图结构的 filters，这使得该方法的泛化能力受限&lt;/p&gt;
            &lt;/blockquote&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;&lt;strong&gt;non-spectral 代表&lt;/strong&gt;&lt;/p&gt;

            &lt;p&gt;[2] Petar Veliˇckovi´c, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. Graph attention networks. In ICLR, 2018.&lt;/p&gt;

            &lt;blockquote&gt;
              &lt;p&gt;通过自监督的方式决定图的连接，使网络更加灵活&lt;/p&gt;
            &lt;/blockquote&gt;
          &lt;/li&gt;
        &lt;/ul&gt;

        &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;用GCN作行为预测，最简单直接的建图方式就是基于骨架&lt;/p&gt;

        &lt;p&gt;缺陷：无法捕捉不相连的关节间的依赖关系&lt;/p&gt;

        &lt;p&gt;&lt;strong&gt;本文方法受 [2] 启发，允许网络自适应地调整各关节点间的连通权重&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;method&quot;&gt;Method&lt;/h2&gt;

&lt;h3 id=&quot;task&quot;&gt;Task&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;已知动作序列 $X_{1:N}=[x_1,x_2,\dots, x_N]$，由 $N$ 个连续的人体姿态组成&lt;/p&gt;

    &lt;p&gt;其中，$x_i\in R^K$，$K$ 为关节点个数&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;预测 $X_{N+1:N+T}$ ，即未来 $T$ 个时间步的动作序列&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$X_{1:N}$ 的单列表示一个时刻的人体姿态，单行则表示一个关节点在 $N$ 时间步内的运动情况&lt;/p&gt;

    &lt;p&gt;记第 $k$ 个关节点对应的行为 $\widetilde x_k = (x_{k,1},x_{k,2},\dots,x_{k,N})$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;temporal-encoding&quot;&gt;Temporal Encoding&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;主要思想&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;将DCT系数作为动作序列的一种编码，旨在捕捉每个关节点的运动模式&lt;/li&gt;
      &lt;li&gt;实验证实，通过丢弃高频项，DCT系数提供了一个更加紧凑的表示，能较好地捕捉到人体运动的平滑性&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;编码&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;给定轨迹 $\widetilde x_k$，时间步 $l$ 对应的DCT系数可以表示为&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;../assets/img/2020-08-08-PR3_pic/image-20200808111235452.png&quot; alt=&quot;image-20200808111235452&quot; style=&quot;zoom: 80%;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;其中，$\delta_{l1}$ 只在 $l=1$ 时取值为1，否则取值为0 【数学细节，用于使DCT-II 成为正交矩阵】&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;对 $l\in{1,2,…,N}$，过滤其中较大的值，在当前任务背景下可以理解为移除高频运动&lt;/p&gt;

      &lt;p&gt;【不是很理解】&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;解码&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;给定DCT系数，原始姿态表示能够通过 逆DCT (IDCT) 变换获得&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;../assets/img/2020-08-08-PR3_pic/image-20200808112415731.png&quot; alt=&quot;image-20200808112415731&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;同样， $n\in{1,2,…,N}$&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;注：若保留所有DCT系数，DCT 与 IDCT 变换前后为无损转换，但截断一些高频项能够防止生成抖动的运动 ( jittery motion )&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;主要步骤&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;给定动作序列 $X_{1:N}$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;将最后一帧 $x_N$ 复制 $T$ 次，构成总长度为 $N+T$ 的动作序列&lt;/p&gt;

        &lt;blockquote&gt;
          &lt;p&gt;将这一复制操作生成的序列作为原始输入，添加残差连接，迫使模型学习“变化”&lt;/p&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;计算该序列的DCT系数作为输入，模型生成预测输出 $X_{1:N+T}$&lt;/p&gt;

        &lt;blockquote&gt;
          &lt;p&gt;输入可以有两种形式：&lt;/p&gt;

          &lt;p&gt;1）将所有关节点的DCT表示堆叠为一个向量&lt;/p&gt;

          &lt;p&gt;2）构成一个 $K×L$ 的矩阵，其中，$K$ 为关节点数，$L$ 为保留的DCT系数数量&lt;/p&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;spatial-encoding&quot;&gt;Spatial Encoding&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;主要思想&lt;/strong&gt;：采用图卷积网络编码空间依赖，允许网络自适应调整连通权重&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;主要步骤&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;初始，假设人体为由 $K$ 个关节点构成的全连接图&lt;/p&gt;

        &lt;p&gt;各连接边的强度由 带权邻接矩阵 $A\in R^{K×K}$ 表示&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;一个图卷积层 $p$ 输入矩阵 $H^{(p)}\in R^{K×F}$ ，在权重矩阵 $W^{(p)}\in R^{F×\hat{F}}$ 的作用下，&lt;/p&gt;

        &lt;p&gt;输出为 $H^{(p+1)}=\sigma(A^{(p)}H^{(p)}W^{(p)})$&lt;/p&gt;

        &lt;blockquote&gt;
          &lt;p&gt;其中，$F$ 为前一层的输出特征数，$A,W$ 为可训练的参数矩阵，$\sigma(\cdot)$ 为激活函数&lt;/p&gt;

          &lt;p&gt;$A$ 理解为任意两关节点间的相互作用关系&lt;/p&gt;

          &lt;p&gt;$W$ 类比全连接网络中，对各特征进行线性组合，输出特征维度为 $\hat{F}$&lt;/p&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;堆叠图卷积层，并添加残差连接&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;network-structure&quot;&gt;Network Structure&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/2020-08-08-PR3_pic/image-20200808154133786.png&quot; alt=&quot;image-20200808154133786&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;外层残差连接，如之前所述，希望网络对 DCT 的”变化”进行建模&lt;/li&gt;
  &lt;li&gt;内层残差连接，则类比传统ResNet中残差边的作用，主要作用是使深度网络的能力不退化&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;training&quot;&gt;Training&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;对角度表示，采用 $l_1$ 损失函数计算平均损失&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;../assets/img/2020-08-08-PR3_pic/image-20200808164738904.png&quot; alt=&quot;image-20200808164738904&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;对3D坐标表示，计算平均关节位置损失 (MPJPE: Mean Per Joint Position Error)&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;../assets/img/2020-08-08-PR3_pic/image-20200808165201617.png&quot; alt=&quot;image-20200808165201617&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;注意到，模型的预测输出是包括已知动作序列在内的整段动作序列 $X_{1:N+T}$&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;这样设计有什么好处？可能是为了使生成的动作序列从总体上看更加平滑&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;与之前的笔记相同，下面只提及部分实验结果&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;主流的评估误差的方式有两种：(1) 基于欧拉角，(2) 基于3D坐标&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;实验分析高误差样本时发现，在指标 (1) 下误差大的样本，在指标 (2) 下并不一定出现高误差&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;../assets/img/2020-08-08-PR3_pic/image-20200808183200654.png&quot; alt=&quot;image-20200808183200654&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;如上图，在指标 (1) 下，三种方法在同一个样本上表现出的误差相似，但在指标 (2) 下，有两种方法的误差明显更小&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;这是由于在角度空间中，动作的表示具有二义性，因此 (1) 可能并不是一个好的评价指标&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;消蚀学习&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;验证 DCT 建模时间信息的有效性&lt;/p&gt;

        &lt;p&gt;验证残差学习的有效性 (以复制最后一个时刻的姿态作序列padding)&lt;/p&gt;

        &lt;p&gt;验证网络残差连接的有效性&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;../assets/img/2020-08-08-PR3_pic/image-20200808184659133.png&quot; alt=&quot;image-20200808184659133&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

        &lt;blockquote&gt;
          &lt;p&gt;上半部分为指标 (1) 的结果，根据前面的分析，可以以下半部分指标 (2) 的结果为准&lt;/p&gt;

          &lt;p&gt;观察可知，&lt;/p&gt;

          &lt;p&gt;1）去掉上述任一模块都将导致模型性能下降，故有效性得证&lt;/p&gt;

          &lt;p&gt;2）对模型性能影响最大的是 padding 操作&lt;/p&gt;
        &lt;/blockquote&gt;

        &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;对比 GCN 与 全连接网络&lt;/p&gt;

        &lt;p&gt;验证允许网络自适应调整连通权重的有效性 (即令 $A$ 可训练)&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;../assets/img/2020-08-08-PR3_pic/image-20200808185135652.png&quot; alt=&quot;image-20200808185135652&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>mettyz</name></author><summary type="html">Human Motion Prediction, 3D-skeleton, DCT, GCN...</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/PR3.png" /><media:content medium="image" url="/PR3.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Paper Reading Record 2</title><link href="/PR2.html" rel="alternate" type="text/html" title="Paper Reading Record 2" /><published>2020-08-06T00:00:00+08:00</published><updated>2020-08-06T00:00:00+08:00</updated><id>/PR2</id><content type="html" xml:base="/PR2.html">&lt;p&gt;QuaterNet: A Quaternion-based Recurrent Model for Human Motion &lt;a href=&quot;https://arxiv.org/pdf/1805.06485.pdf&quot;&gt;[Paper]&lt;/a&gt;&lt;/p&gt;

&lt;!--more--&gt;

&lt;blockquote&gt;
  &lt;p&gt;写在前面：文中包含个人理解，不保证正确，如理解有误，欢迎指正。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;main-idea&quot;&gt;Main Idea&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;基于&lt;strong&gt;四元数&lt;/strong&gt;构建模型，在描述3D运动上有天然优势&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;损失函数&lt;strong&gt;采用关节点位置误差&lt;/strong&gt;（将 预测旋转 与 预测绝对位置 两类方法的优势相结合）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;为短期预测与长期预测分别构建了模型&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;对长期预测，加入了人工特征控制（轨迹、速度、面部朝向、步频）&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;残差连接&lt;/strong&gt;在短期预测中有优势，在长期预测中不适用&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;人类行为是一个具有&lt;strong&gt;高度内在不确定性&lt;/strong&gt;的随机序列过程，这为长期预测带来挑战&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;短期预测&lt;/strong&gt;通常被看作&lt;em&gt;预测&lt;/em&gt; 任务 (short-term prediction)&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;能够通过将预测结果与参考结果对比来定量计算损失&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;长期预测&lt;/strong&gt;通常被看作&lt;em&gt;生成&lt;/em&gt; 任务 (long-term generation)&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;定量评估较为困难，可以让人来评估生成质量&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;related-work&quot;&gt;Related Work&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;行为预测的两大类方式 —— &lt;em&gt;Joint Rotations&lt;/em&gt; v.s. &lt;em&gt;Joint Positions&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;预测关节点的旋转 (Joint Rotations)&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;优势：自然地以骨架作为约束，避免了躯干伸缩及超出关节范围的运动等问题&lt;/p&gt;

        &lt;p&gt;缺陷：&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;
            &lt;p&gt;通常计算各关节点的平均损失，即不同关节点的权重相同&lt;/p&gt;

            &lt;blockquote&gt;
              &lt;p&gt;实际上，不同关节点的错位对姿态的影响程度不同，如连接躯干及四肢的关节点对姿态的影响强于四肢末端的关节点&lt;/p&gt;
            &lt;/blockquote&gt;

            &lt;p&gt;这可能导致模型的预测结果在重要关节上出现较大误差，影响视觉效果&lt;/p&gt;

            &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;预测关节点的位置 (Joint Positions)&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;优势：极小化绝对位置损失，避免了上述缺陷&lt;/p&gt;

        &lt;p&gt;缺陷：缺乏骨架约束，四肢躯干可能出现变形，需要将预测结果作重映射调整，增加训练难度，带来额外开销，且重映射可能导致动作的不连续&lt;/p&gt;

        &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;利用残差连接帮助训练&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;直观上理解，残差连接迫使网络预测变化的 “速度 (velocities) “ 而不是 “值 (absolute values)”&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;../assets/img/2020-08-06-PR2_pic/image-20200806175039090.png&quot; alt=&quot;image-20200806175039090&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

        &lt;blockquote&gt;
          &lt;p&gt;[1] Julieta Martinez, Michael J. Black, and Javier Romero. On human motion prediction using recurrent neural networks. In Conference on Vision and Pattern Recognition (CVPR), 2017.&lt;/p&gt;
        &lt;/blockquote&gt;

        &lt;ul&gt;
          &lt;li&gt;
            &lt;p&gt;优势：使得需要预测的值被限制在较小的范围内，有助于网络收敛&lt;/p&gt;

            &lt;p&gt;缺陷：在长期预测任务上表现不稳定，由于误差累积可能导致糟糕结果&lt;/p&gt;

            &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;建模方法&lt;/strong&gt;&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;
            &lt;p&gt;早期方法：每步输入ground truth motion作为教师监督&lt;/p&gt;

            &lt;p&gt;缺陷：模型不具备错误恢复能力&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;[1] 方法：每步输入上一步的预测结果&lt;/p&gt;

            &lt;p&gt;缺陷：如果用于长期预测，累积损失将会很大，导致模型将难以训练&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;任务分解法：将长期预测任务分解为 1) 定义运动轨迹 2) 用 footsteps 标注轨迹 3) 生成姿态序列&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;method&quot;&gt;Method&lt;/h2&gt;

&lt;h3 id=&quot;architecture&quot;&gt;Architecture&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;../assets/img/2020-08-06-PR2_pic/image-20200806193719030.png&quot; alt=&quot;image-20200806193719030&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;构建使用双层GRU的自回归模型&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;与 [1] 不同，团队发现增加第二层GRU具有经验优势，但不必增加到三层&lt;/p&gt;

      &lt;p&gt;设置 hidden size = 1000&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Short-term Prediction：每步输入上一步的预测结果&lt;/p&gt;

    &lt;p&gt;Long-term Generation：每步以概率 p 输入 ground truth 监督&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;随着训练过程的进行，p 从1开始递减： $p_{t+1} = \beta p_t$，其中 $\beta =0.995$&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Rotations：由单位四元数描述的关节旋转状态&lt;/p&gt;

    &lt;p&gt;Translations：用于建模高频运动细节，使生成的动画更加逼真&lt;/p&gt;

    &lt;p&gt;Controls：轨迹控制信息&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;Translations 和 Controls 的数学细节没太看懂&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;对短期预测采用了QMul，即训练模型预测从当前姿态到下一姿态的变换角度&lt;/p&gt;

    &lt;p&gt;对长期预测未采用QMul，即训练模型预测准确的下一姿态&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;如下图实验显示，残差连接用于长期预测将累积误差，导致模型不稳定，&lt;/p&gt;

      &lt;p&gt;而不采用残差的方法在长期预测中表现出优势&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;&lt;img src=&quot;../assets/img/2020-08-06-PR2_pic/image-20200806234435170.png&quot; alt=&quot;image-20200806234435170&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;rotation-parameterization&quot;&gt;Rotation Parameterization&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;欧拉角，指数映射&lt;/strong&gt;  $ R^3$&lt;/p&gt;

    &lt;p&gt;缺陷：表示不唯一 ($\alpha=\alpha+2\pi n$)、表示空间不连续、奇点 (gimbal loack 万向锁)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;四元数&lt;/strong&gt;  $ R^4 $&lt;/p&gt;

    &lt;p&gt;优势：不存在上述三维空间中的问题，且数值更加稳定、计算更加高效&lt;/p&gt;

    &lt;p&gt;缺陷：需要保证单位长度，因此每步都需要进行正则化&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;对 $q=w+xi+yj+zk$，要求 $||q||=\sqrt{w^2+x^2+y^2+z^2}=1$&lt;/p&gt;

      &lt;p&gt;本文为损失函数添加了正则约束 $\lambda(w^2+x^2+y^2+z^2-1)$ ，设置 $\lambda=0.01$&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;forward-kinematics-loss&quot;&gt;Forward Kinematics Loss&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;直接对角度进行回归可能会导致关键关节点出现偏差，进而显著影响整体姿态效果&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;本文的损失函数根据预测出的四元数计算出关节点的预测位置，再计算欧几里得距离作为损失&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;&lt;strong&gt;Forward kinematics&lt;/strong&gt; refers to the use of the kinematic equations of a robot to compute the position of the end-effector from specified values for the joint parameters. &lt;a href=&quot;https://en.wikipedia.org/wiki/Forward_kinematics&quot;&gt;Wiki&lt;/a&gt;&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;long-term-generation&quot;&gt;Long-Term Generation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;任务定义：给定平均速度与运动轨迹，生成姿态序列&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;任务分解&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;1）沿着轨迹定义参数：角色面对的方向，局部速度，脚步频率&lt;/p&gt;

        &lt;blockquote&gt;
          &lt;p&gt;&lt;strong&gt;轨迹表示&lt;/strong&gt;&lt;/p&gt;

          &lt;p&gt;可视为分段线性样条 piecewise linear spline，可理解为分段线性函数&lt;/p&gt;

          &lt;p&gt;在本任务背景下，轨迹可以按等长时间分段，相当于在每小段时间内面向某个方向，以某个速度前进&lt;/p&gt;
        &lt;/blockquote&gt;

        &lt;blockquote&gt;
          &lt;p&gt;&lt;strong&gt;pace network&lt;/strong&gt;&lt;/p&gt;

          &lt;p&gt;参数可以人工设置，也可以通过训练速度网络(pace network)自动生成&lt;/p&gt;

          &lt;p&gt;采用单层GRU, hidden size = 30，输入轨迹曲线与上一步的隐状态，预测上述参数&lt;/p&gt;

          &lt;p&gt;可以根据 在线/离线场景 设置 单向/双向GRU&lt;/p&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;2）预测姿态序列 (pose network，如架构图所示)&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;下述只提及文中部分实验结果&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;证实残差连接在短期预测中的优势&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;../assets/img/2020-08-06-PR2_pic/image-20200806235125169.png&quot; alt=&quot;image-20200806235125169&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;展示 pace network 的效果&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;../assets/img/2020-08-06-PR2_pic/image-20200807001138289.png&quot; alt=&quot;image-20200807001138289&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;黑线：轨迹曲率，作为输入，尖锐部分表示有大的转向&lt;/p&gt;

    &lt;p&gt;蓝、绿线：可以看到在转弯处，速度明显减慢、步频略微加快，合理&lt;/p&gt;

    &lt;p&gt;橙线：面部朝向变换合理&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>mettyz</name></author><summary type="html">Human Motion Prediction, 3D-skeleton, Quaternion, RNN...</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/PR2.png" /><media:content medium="image" url="/PR2.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Paper Reading Record 1</title><link href="/PR1.html" rel="alternate" type="text/html" title="Paper Reading Record 1" /><published>2020-07-18T00:00:00+08:00</published><updated>2020-07-18T00:00:00+08:00</updated><id>/PR1</id><content type="html" xml:base="/PR1.html">&lt;p&gt;(CVPR2020) &lt;a href=&quot;https://openaccess.thecvf.com/content_CVPR_2020/papers/Yu_Weakly_Supervised_Discriminative_Feature_Learning_With_State_Information_for_Person_CVPR_2020_paper.pdf&quot;&gt;[Paper]&lt;/a&gt;&lt;/p&gt;

&lt;!--more--&gt;

&lt;blockquote&gt;
  &lt;p&gt;写在前面：文中包含个人理解，不保证正确，如理解有误，欢迎指正。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;main-idea&quot;&gt;Main Idea&lt;/h2&gt;

&lt;p&gt;利用状态信息作为弱监督信号，来学习能够区分人身份的特征&lt;/p&gt;

&lt;p&gt;旨在处理由不同状态带来的视觉差异对模型的影响&lt;/p&gt;

&lt;p&gt;利用WFDR将较强烈的特征畸变变得温和，利用WDBR矫正较温和的特征畸变&lt;/p&gt;

&lt;h2 id=&quot;keywords&quot;&gt;Keywords&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;State Information：e.g. camera views, poses&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;论文中所利用的状态信息，是指那些&lt;strong&gt;无需额外人工标记&lt;/strong&gt;的，在数据集收集过程中就自带的状态标签，如拍摄的机位编号，拍摄的角度等&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;WDBR: Weakly supervised decision boundary rectification 【弱监督的决策边界矫正】&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;WFDR: Weakly supervised feature drift regularization 【弱监督的特征偏移正则化】&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;MPI: Maximum Predominance Index 【最大优势指数】&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;visual discrepancy，feature distortion&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;pseudo class = surrogate class&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;methods&quot;&gt;Methods&lt;/h2&gt;

&lt;h3 id=&quot;pseudo-label-model&quot;&gt;Pseudo label model&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;指论文采用的&lt;strong&gt;训练策略&lt;/strong&gt;，采用了聚类的思想&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;基本思路&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;初始设置 $K$ 个伪类，$K&amp;gt;$ 最大类别数，极端假设下，可以假设每张图像属于一个伪类&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;例：对于RE-ID，最大类别数即为数据集中不同人的数目，伪类的含义为身份id&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;通过WDBR调整边界，有些伪类可能收缩到一个点，相当于被作废&lt;/p&gt;

    &lt;p&gt;通过极小化分类损失训练模型，直观意义上，就是让样本尽可能靠近它被分到的伪类中心&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;拉近类内距离，拉远类间距离，提升特征空间的模块化程度&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/img/PR1_pic/image-20200719112833305.png&quot; alt=&quot;image-20200719112833305&quot; style=&quot;zoom: 80%;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;训练目标&lt;/strong&gt;：特征提取器 $f$ ，用于提取可以区分身份的特征&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;利用模型将图像映射到状态空间中，同一身份的样本应该相互靠近&lt;/p&gt;

      &lt;p&gt;进一步可利用聚类算法分类&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;符号说明&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;$u_i$ ：一个无标签的图像样本，训练集中共有 $N$ 个样本&lt;/p&gt;

    &lt;p&gt;$x$ ：特征空间中的向量表示&lt;/p&gt;

    &lt;p&gt;$\theta$：模型 $f$ 的参数&lt;/p&gt;

    &lt;p&gt;$s_i\in{1,\dots,J}$ ：样本 $i$ 的状态信息取值，有 $J$  种&lt;/p&gt;

    &lt;p&gt;$\mu$ ：伪类分类器，即聚类中心&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;$x^T\mu_j$ 衡量了特征向量 $x$ 与聚类中心 $\mu_j$ 的相似程度，可看作将 $x$ 分到伪类 $j$ 的得分&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;wdbr&quot;&gt;WDBR&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;在&lt;strong&gt;较温和&lt;/strong&gt;的视觉差异的影响下，特征空间中，无标签样本可能稍微偏离正确的区域，到附近区域中&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;解决思路：通过调整决策边界，使无标签样本能够落在正确区域内&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/img/PR1_pic/WDBR.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;定义MPI&lt;/strong&gt; (最大优势指数)&lt;/p&gt;

    &lt;p&gt;用于量化一个伪类受某种状态支配的程度&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;MPI越大，说明这些样本之所以被归为这一类，很可能是因为受到了这个状态的影响，而这个状态本身不是我们期望模型用于分类的特征&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;

    &lt;p&gt;具体定义为&lt;strong&gt;伪类中具有支配状态的样本的占比&lt;/strong&gt;，形式化如下&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/img/PR1_pic/MPI.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;其中，分母表示当前伪类k中样本个数，分子表示在某一状态上取值相同的最大子集&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;分子 = $max_j$ (伪类k中状态取值为 $j$ 的样本个数)&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;矫正策略&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;利用下述分类公式，可&lt;strong&gt;将 MPI 值超过阈值的伪类收缩&lt;/strong&gt;，甚至作废&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;$a$ 可视作&lt;strong&gt;矫正力度&lt;/strong&gt;，$b$ 可视作&lt;strong&gt;矫正阈值&lt;/strong&gt;&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;可以看到，在hard设定下，超过阈值的伪类 $p(k)=0$，此时不会有样本被分到该类，即实现了将该类作废&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/img/PR1_pic/image-20200717084810814.png&quot; style=&quot;zoom: 67%;&quot; /&gt; &lt;img src=&quot;/assets/img/PR1_pic/image-20200717085548489.png&quot; style=&quot;zoom: 45%;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;小结&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;WDBR 训练模型倾向于扩大 MPI 值较小的伪类的作用域&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;MPI 值较小，意味着这个伪类当中的样本在各个状态上的分布较为均衡，也就意味着它们被分在一起不是因为受到这些状态信息的影响&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;如此训练出的模型将倾向于提取对状态信息不敏感的特征&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;wfdr&quot;&gt;WFDR&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;当视觉差异影响&lt;strong&gt;较严重&lt;/strong&gt;时，样本可能会严重偏离正确区域&lt;/p&gt;

    &lt;p&gt;此时，若想使用WDBR，需要先将特征畸变变得温和 (significant $\to$ moderate)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;解决思路&lt;/p&gt;

    &lt;p&gt;受某种状态影响导致的特征畸变通常遵循一个特定的模式（如照明不足将抑制所有视觉特征），这会导致特征空间中，处于该状态的样本向同一个方向偏移&lt;/p&gt;

    &lt;p&gt;因此，我们可以在全局尺度上捕获这种偏移，然后把它“拉回来”&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/img/PR1_pic/WFDR.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;如何捕获？&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;捕捉状态子分布  ( state sub-distribution ) 与全局样本特征分布之间的偏差&lt;/p&gt;

    &lt;p&gt;假设 $P(Q_j)$  为状态取值为 $j$ 的样本的分布情况，$P(X)$ 为所有样本的分布情况，&lt;/p&gt;

    &lt;p&gt;畸变将导致 $P(Q_j)$ 偏离 $P(X)$&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;矫正策略&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;拉近两分布的距离，对应损失函数如下：&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/img/PR1_pic/image-20200717095414630.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/img/PR1_pic/image-20200717095435308.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;小结&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;可以看出，损失函数对两个分布之间的距离进行惩罚，并调整参数 $\theta$&lt;/p&gt;

        &lt;blockquote&gt;
          &lt;p&gt;$\theta$ 是目标特征提取器的参数&lt;/p&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;直观上，这将使模型在提取特征向量时，减少对状态的关注，即尽量不让这个状态影响到特征向量的分布&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;loss-function&quot;&gt;Loss Function&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/PR1_pic/image-20200719113120576.png&quot; alt=&quot;image-20200719113120576&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Tasks&lt;/strong&gt;：person re-identification (&lt;strong&gt;RE-ID&lt;/strong&gt;) and pose-invariant face recognition (&lt;strong&gt;PIFR&lt;/strong&gt;)&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;RE-ID：将不同镜头下拍摄到的人进行身份匹配，对应状态信息：相机标签&lt;/p&gt;

      &lt;p&gt;PIFR：将不同姿势的人脸进行匹配，对应状态信息：姿势（不同角度/正侧面）&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/img/PR1_pic/image-20200719115228806.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;消蚀实验等验证模型有效性与准确性的实验不再赘述，先说&lt;strong&gt;结论&lt;/strong&gt;：&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;动态调整聚类中心、WDBR、WFDR均有效&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;WDBR 与 WFDR 的能力能够互为补充&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;对样本不平衡的数据集，WDBR 的 hard 矫正可能更加有效，而对于平衡的数据集，soft 矫正能够体现出优势&lt;/p&gt;

        &lt;blockquote&gt;
          &lt;p&gt;平衡：数据集中每个人有多少张照片是固定的&lt;/p&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;分析一些实验现象&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/img/PR1_pic/image-20200719115725587.png&quot; alt=&quot;image-20200719115725587&quot; style=&quot;zoom: 70%;&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;在 Multi-PIE 中，WFDR没有起到很大作用&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;可能原因：在 Multi-PIE 中，人脸角度变化是连续的，因此特征本就没有很大的偏移&lt;/p&gt;

        &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;soft 矫正在 PIFR 任务上表现较好，而 hard 矫正在 RE-ID 任务上表现较好&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;可能原因：RE-ID 数据集中，不同身份的人的图像数量不均衡&lt;/p&gt;

        &lt;p&gt;&lt;strong&gt;soft 矫正器&lt;/strong&gt; 的权重变化是一个连续的过程，它将更倾向于状态均衡程度高的伪类，因此机位照片多的人将更可能获得大权重，这是不公平的&lt;/p&gt;

        &lt;blockquote&gt;
          &lt;p&gt;如果一个人只有2个机位的照片，则他的 MPI 值至少是 1/2，而有6个机位照片的人，MPI 值最小是 1/6，因此能够获得更大的 $p(k)$&lt;/p&gt;
        &lt;/blockquote&gt;

        &lt;p&gt;&lt;strong&gt;hard 矫正器&lt;/strong&gt; 是一个阶跃函数，仅仅使具有很高 MPI 值的伪类失效，对状态均衡的&lt;strong&gt;程度&lt;/strong&gt;没有偏好&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;my-thoughts&quot;&gt;My Thoughts&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;状态信息的寻找与利用依靠人工设计，有没有可能让网络自己衡量特征对任务的帮助程度？&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;在浅层网络中，特征向量的每一个维度可能对应着某一种状态属性&lt;/p&gt;

      &lt;p&gt;随着网络的加深，每个维度则可能编码着多种状态的综合属性&lt;/p&gt;

      &lt;p&gt;如果修改一个特征，能够让一组样本发生整体的偏移，而样本之间的相对距离变化不大，是否能够说明这个特征是某种对区分样本帮助不大的状态特征？&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;训练集中的人和测试集中的人没有重合&lt;/strong&gt;&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;很关键，这样一来能够测试出模型学习到的特征是否是关注于”区分”，而非提取这个人本身的特征&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>mettyz</name></author><summary type="html">CVPR2020, Weakly supervised, State information...</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/PR1.png" /><media:content medium="image" url="/PR1.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>